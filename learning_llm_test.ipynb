{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302710b4-7b39-41dd-9c27-98a7e728313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 실제 저장 경로: /mnt/ssd/1/hub/models--Bllossom--llama-3.2-Korean-Bllossom-3B/snapshots/e68fbb0d9c2a4031b0d61b14014eac1a4810ac2e\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "\n",
    "# 모델 ID 설정 (Hugging Face에서 다운로드한 모델명)\n",
    "model_id = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "\n",
    "# 모델의 주요 파일 (config.json)을 기준으로 경로 찾기\n",
    "model_cache_path = os.path.dirname(hf_hub_download(model_id, filename=\"config.json\"))\n",
    "\n",
    "print(f\"모델의 실제 저장 경로: {model_cache_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951a1276-c144-4acb-80f9-14f6d4225083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iljoo/.local/share/virtualenvs/sanguk-WEz904Hl/lib/python3.12/site-packages/triton/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import triton\n",
    "print(triton.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eda4e1",
   "metadata": {},
   "source": [
    "### 데이터셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27522ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 498:\n",
      "Formatted Text\n",
      "Instruction:\n",
      "이 공식 자료를 토대로, 양사의 디지털 전환 전략은 어떻게 구분될 수 있을까요?\n",
      "\n",
      "Context (for training only):\n",
      "공식 홈페이지와 최근 블로그 포스트에 따르면, 일주지앤에스는 ERP 및 MES 시스템을 도입하여 조선해양 분야의 디지털 전환을 선도하고 있고, 티허브는 IoT 기술을 접목한 실시간 모니터링 서비스를 통해 시장 경쟁력을 강화하고 있다.\n",
      "\n",
      "Response:\n",
      "ERP/MES 기반 조선해양 디지털 전환과 IoT 실시간 모니터링 서비스\n",
      "\n",
      "Answer Start Indices (for training only):\n",
      "[60, 130]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "데이터셋 생성 완료\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from datasets import Dataset\n",
    "\n",
    "# JSONLines 파일 경로\n",
    "jsonl_path = \"/mnt/ssd/1/sanguk/dataset/iljoo_dataset.jsonl\"\n",
    "\n",
    "# 원하는 라인 번호\n",
    "target_line = 498\n",
    "\n",
    "# JSONLines 파일을 읽어서 데이터셋 생성\n",
    "dataset_list_check = []\n",
    "\n",
    "with jsonlines.open(jsonl_path) as f:\n",
    "    for lineno, line in enumerate(f.iter(), start=1):\n",
    "        if lineno == target_line:  # 원하는 라인 번호에 도달하면\n",
    "            try:\n",
    "                instruction = line.get(\"question\", \"\")\n",
    "                context = line.get(\"context\", \"\")\n",
    "\n",
    "                response_list = line.get(\"answers\", {}).get(\"text\", [\"\"])\n",
    "                response = \", \".join(response_list)\n",
    "                answer_starts = line.get(\"answers\", {}).get(\"answer_start\", [])\n",
    "\n",
    "                # formatted_text: Context와 Answer_start 정보는 학습 과정에서만 활용되며,\n",
    "                # 실제 출력에는 사용되지 않습니다.\n",
    "                formatted_text_check = (\n",
    "                    f\"Instruction:\\n{instruction}\\n\\n\"\n",
    "                    f\"Context (for training only):\\n{context}\\n\\n\"\n",
    "                    f\"Response:\\n{response}\\n\\n\"\n",
    "                    f\"Answer Start Indices (for training only):\\n{answer_starts}\"\n",
    "                )\n",
    "                \n",
    "                # dataset_list에는 오직 formatted_text만 저장합니다.\n",
    "                dataset_list_check.append({\"text\": formatted_text_check})\n",
    "\n",
    "                print(f\"Line {lineno}:\")  # 현재 처리 중인 line 번호 출력\n",
    "                print(f\"Formatted Text\\n{formatted_text_check}\")\n",
    "                print(\"-\" * 200)  # 구분선 추가\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error at line {lineno}: {e}\")\n",
    "\n",
    "            break  # 원하는 라인을 찾았으므로 루프 종료\n",
    "        elif lineno > target_line:  # target_line이 파일에 없는 경우를 대비\n",
    "            print(f\"Line {target_line} not found in the file.\")\n",
    "            break\n",
    "\n",
    "print(\"데이터셋 생성 완료\")\n",
    "\n",
    "# Hugging Face Dataset으로 변환\n",
    "dataset_check = Dataset.from_list(dataset_list_check)\n",
    "\n",
    "# 데이터셋 정보 확인\n",
    "print(dataset_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a68b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 생성 완료\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from datasets import Dataset\n",
    "\n",
    "# JSONLines 파일 경로\n",
    "jsonl_path = \"/mnt/ssd/1/sanguk/dataset/iljoo_dataset.jsonl\"\n",
    "\n",
    "# JSONLines 파일을 읽어서 formatted_text만 포함하는 데이터셋 생성\n",
    "dataset_list = []\n",
    "with jsonlines.open(jsonl_path) as f:\n",
    "    for lineno, line in enumerate(f.iter(), start=1):\n",
    "        try:\n",
    "            # 각 줄의 데이터를 이용해 템플릿에 맞는 형식의 문자열 생성\n",
    "            instruction = line.get(\"question\", \"\")\n",
    "            context = line.get(\"context\", \"\")\n",
    "            \n",
    "            response_list = line.get(\"answers\", {}).get(\"text\", [\"\"])\n",
    "            response = \", \".join(response_list)\n",
    "            answer_starts = line.get(\"answers\", {}).get(\"answer_start\", [])\n",
    "            \n",
    "            # formatted_text 생성:\n",
    "            # - <|instruction|> ~ <|end_instruction|>: 질문 영역\n",
    "            # - <|context|> ~ <|end_context|> 및 <|answer_start|> ~ <|end_answer_start|>는 참고(reference) 정보로만 사용됩니다.\n",
    "            # - 아래 안내문을 통해 모델에게 참고 정보는 답변 생성에만 사용하고, 최종 출력에는 포함하지 말 것을 지시합니다.\n",
    "            formatted_text = (\n",
    "                f\"<|instruction|>{instruction}<|end_instruction|>\\n\"\n",
    "                f\"<|context|>{context}<|end_context|>\\n\"\n",
    "                f\"<|answer_start|>{answer_starts}<|end_answer_start|>\\n\"\n",
    "                \"Note: The context and answer_start above are provided for reference only. \"\n",
    "                \"When generating an answer, please base your response solely on the instruction and do not include the reference information in your final output.\\n\"\n",
    "                f\"<|response|>{response}<|end_response|>\"\n",
    "            )\n",
    "            \n",
    "            # dataset_list에는 오직 formatted_text만 저장합니다.\n",
    "            dataset_list.append({\"text\": formatted_text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error at line {lineno}: {e}\")\n",
    "\n",
    "print(\"데이터셋 생성 완료\")\n",
    "\n",
    "# Hugging Face Dataset으로 변환\n",
    "dataset = Dataset.from_list(dataset_list)\n",
    "\n",
    "# 데이터셋 정보 확인\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf05dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b8a57475f94c2ca3b1b4ca2a063806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e9190a715f4f0e92f2c4c751b83ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 새로운 경로로 저장되었습니다: /mnt/ssd/1/hub/models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B_bf16_lr16_qlr4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594dfbea02ef4dd5b7a3215814e48173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70e2bf5661e45d3aaecf7d8d20e4f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning 시작...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 09:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>13.568000</td>\n",
       "      <td>13.575642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>13.285500</td>\n",
       "      <td>12.690991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>10.829600</td>\n",
       "      <td>7.264856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.129400</td>\n",
       "      <td>33.901634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.390500</td>\n",
       "      <td>1.075025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.000500</td>\n",
       "      <td>0.921197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.910300</td>\n",
       "      <td>0.913150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.906131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.938200</td>\n",
       "      <td>0.899435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.187100</td>\n",
       "      <td>1.843563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>6.454600</td>\n",
       "      <td>6.786142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.935500</td>\n",
       "      <td>0.884759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.570800</td>\n",
       "      <td>6.087545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.924400</td>\n",
       "      <td>1.783353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.764900</td>\n",
       "      <td>1.694682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.504700</td>\n",
       "      <td>0.838655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.840906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.833100</td>\n",
       "      <td>0.842298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.797700</td>\n",
       "      <td>0.833769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.497400</td>\n",
       "      <td>0.845206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>0.839291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.030800</td>\n",
       "      <td>0.834402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.899700</td>\n",
       "      <td>0.819997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.072500</td>\n",
       "      <td>0.821329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>0.818316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.466200</td>\n",
       "      <td>0.818506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.757400</td>\n",
       "      <td>0.821951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.153600</td>\n",
       "      <td>0.817932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.814876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.793800</td>\n",
       "      <td>0.814950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the best model at /mnt/ssd/1/hub/models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B_bf16_lr16_qlr4/checkpoint-580/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning 완료!\n",
      "Fine-tuned 모델이 /mnt/ssd/1/hub/models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B_bf16_lr16_qlr4에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer,\n",
    "                          BitsAndBytesConfig, EarlyStoppingCallback)\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.\")\n",
    "\n",
    "model_id = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "# 전체 모델 다운로드를 위한 캐시 경로 확인\n",
    "original_model_path = snapshot_download(repo_id=model_id)\n",
    "\n",
    "# 새로운 모델 저장 경로 (bf16 환경용 경로, 추후 저장 시 사용)\n",
    "new_model_path = os.path.join(\"/mnt/ssd/1/hub\", \"models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B_bf16_lr16_qlr4\")\n",
    "\n",
    "# 기존 모델과 토크나이저 로드 (bfloat16 사용)\n",
    "tokenizer = AutoTokenizer.from_pretrained(original_model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    original_model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 새로운 경로가 없으면 생성 후 저장\n",
    "if not os.path.exists(new_model_path):\n",
    "    os.makedirs(new_model_path, exist_ok=True)\n",
    "model.save_pretrained(new_model_path)\n",
    "tokenizer.save_pretrained(new_model_path)\n",
    "print(f\"모델이 새로운 경로로 저장되었습니다: {new_model_path}\")\n",
    "\n",
    "# QLoRA: 4-bit 양자화 설정 적용하여 모델 재로드\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    # load_in_8bit=True,\n",
    "    # bnb_8bit_compute_dtype=torch.loat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    new_model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "# k-bit 학습 준비 (QLoRA 최적화)\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# 특정 레이어만 학습 가능하도록 설정 (q_proj, k_proj, v_proj, o_proj)\n",
    "for name, param in model.named_parameters():\n",
    "    if any(x in name for x in [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]):\n",
    "        param.data = param.data.to(torch.float32)  # 계산 안정성을 위해 float32 변환\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# LoRA 설정: 일부 파라미터만 업데이트하도록 구성\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "def preprocess_data(example):\n",
    "    # formatted_text가 \"text\" 필드에 저장되어 있으므로 이를 토크나이즈합니다.\n",
    "    inputs = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=2028,\n",
    "    )\n",
    "    # 언어 모델 학습을 위해 입력 토큰을 그대로 레이블로 사용 (필요에 따라 수정 가능)\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()\n",
    "    return inputs\n",
    "\n",
    "fine_tuning_dataset = dataset.map(preprocess_data)\n",
    "\n",
    "# 8:2 비율로 데이터셋 분리 (train: 80%, eval: 20%)\n",
    "split_datasets = fine_tuning_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_datasets[\"train\"]\n",
    "eval_dataset = split_datasets[\"test\"]\n",
    "\n",
    "# -------------------------\n",
    "# Trainer 설정 및 학습 진행\n",
    "# -------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=new_model_path,\n",
    "    per_device_train_batch_size=2,  # 메모리 허용 범위 내에서 증가 가능\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,             # 학습률 명시\n",
    "    warmup_steps=100,               # 필요에 따라 warmup 단계 추가\n",
    "    weight_decay=0.01,              # 오버피팅 방지\n",
    "    logging_steps=20,               # 너무 잦은 로깅은 오버헤드 발생\n",
    "    save_total_limit=2,\n",
    "    save_steps=40,                  # 체크포인트 저장 간격 조정\n",
    "    eval_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",   # 평가 기준 지정\n",
    "    greater_is_better=False,      \n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    save_on_each_node=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=60)]\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning 시작...\")\n",
    "trainer.train()\n",
    "print(\"Fine-tuning 완료!\")\n",
    "\n",
    "trainer.save_model(new_model_path)\n",
    "model.save_pretrained(new_model_path)\n",
    "tokenizer.save_pretrained(new_model_path)\n",
    "print(f\"Fine-tuned 모델이 {new_model_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6017202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "# from datasets import Dataset\n",
    "# from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# # 모델 ID (Hugging Face에서 다운로드한 모델명)\n",
    "# model_id = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "\n",
    "# # 캐시된 모델의 실제 경로 찾기 (전체 다운로드)\n",
    "# original_model_path = snapshot_download(repo_id=model_id)\n",
    "\n",
    "# # 새로운 모델 저장 경로 지정\n",
    "# # new_model_path = os.path.expanduser(\"~/.cache/huggingface/hub/models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B\")\n",
    "# new_model_path = os.path.join(\"/mnt/ssd/1/hub\", \"models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B_bf16\")\n",
    "\n",
    "# # 기존 모델 & 토크나이저 로드\n",
    "# tokenizer = AutoTokenizer.from_pretrained(original_model_path)\n",
    "# tokenizer.pad_token = tokenizer.eos_token \n",
    "# model = AutoModelForCausalLM.from_pretrained(original_model_path, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# # 새로운 경로가 존재하는지 확인 후 저장\n",
    "# if not os.path.exists(new_model_path):\n",
    "#     os.makedirs(new_model_path, exist_ok=True)\n",
    "\n",
    "# # 새로운 모델 디렉토리에 저장\n",
    "# model.save_pretrained(new_model_path)\n",
    "# tokenizer.save_pretrained(new_model_path)\n",
    "\n",
    "# print(f\"모델이 새로운 경로로 저장되었습니다: {new_model_path}\")\n",
    "\n",
    "# # QLoRA 적용하여 모델 로드 (4-bit 양자화)\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.float16\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     new_model_path,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "#     quantization_config=bnb_config  # 올바른 설정 적용\n",
    "# )\n",
    "\n",
    "# # QLoRA 최적화 적용\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# # 특정 레이어만 학습 가능하도록 설정 (부분 Fine-tuning 적용)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"q_proj\" in name or \"v_proj\" in name:  # 일부 레이어만 학습\n",
    "#         param.data = param.data.to(torch.float32)  # float 변환 \n",
    "#         param.requires_grad = True  # 학습 가능하도록 설정\n",
    "#     else:\n",
    "#         param.requires_grad = False  # 동결 (Frozen)\n",
    "\n",
    "# # LoRA 설정 (작은 가중치만 학습)\n",
    "# lora_config = LoraConfig(\n",
    "#     r=8,  # 작은 가중치 차원\n",
    "#     lora_alpha=32,  # LoRA 학습률 스케일\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],  # 적은 파라미터만 학습\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "# )\n",
    "\n",
    "# # 모델을 LoRA 방식으로 변환\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # 3개의 커스텀 데이터 (SQuAD 스타일)\n",
    "# custom_data = [\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 부산광역시 동래구 사직동 석사로 10-1 률영빌딩 5층에 본사를 두고 있는 디지털 혁신 전문기업이다. \",\n",
    "#         \"question\": \"일주지앤에스 알아?\",\n",
    "#         \"answers\": {\"text\": [\"부산에 위치한 디지털 혁신 전문기업\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"부산 디지털 혁신 전문기업의 대표이사는 김정엽 이다. 김정엽 대표는 경북대학교 통계학과 출신으로 현대중공업 전산실에서 근무하다가 일주지앤에스를 창업하였으며, 티허브의 공동 태표이사이기도 하다.\",\n",
    "#         \"question\": \"일주지앤에스 대표는?\",\n",
    "#         \"answers\": {\"text\": [\"김정엽\"], \"answer_start\": [22]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스 김도현 이사는 일주지앤에스의 미래기술연구소 소장이다. 김도현 이사는 AI,빅데이터,융합기술 전문가이다.\",\n",
    "#         \"question\": \"일주지앤에스 김도현 알아?\",\n",
    "#         \"answers\": {\"text\": [\"일주지앤에스의 김도현 이사는 미래기술연구소 소장이다\"], \"answer_start\": [0]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 2006년 6월 29일에 설립된 IT 서비스 전문기업으로, 부산광역시 동래구 사직동 석사로 10-1 률영빌딩 5층에 본사를 두고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스는 언제 설립되었나요?\",\n",
    "#         \"answers\": {\"text\": [\"2006년 6월 29일\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 정보시스템 통합, 소프트웨어 구축, 정보통신공사, 컴퓨터 도매, 연구개발, 시각 디자인, 전자부품 개발 및 제조 등의 다양한 사업을 영위하고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스의 주요 사업 분야는 무엇인가요?\",\n",
    "#         \"answers\": {\"text\": [\"정보시스템 통합, 소프트웨어 구축, 정보통신공사, 컴퓨터 도매, 연구개발, 시각 디자인, 전자부품 개발 및 제조\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 스마트 공장 구축, 시스템 통합(SI), IT 아웃소싱, 솔루션 개발, 컨설팅 사업 등을 주축으로 종합 정보 서비스를 제공하고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 제공하는 서비스는 무엇인가요?\",\n",
    "#         \"answers\": {\"text\": [\"스마트 공장 구축, 시스템 통합(SI), IT 아웃소싱, 솔루션 개발, 컨설팅 사업\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 현대일렉트릭, 휴먼중공업, 삼강엠엔티 등과 스마트 공장 구축 프로젝트를 성공적으로 수행하였습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 스마트 공장 구축을 수행한 기업은 어디인가요?\",\n",
    "#         \"answers\": {\"text\": [\"현대일렉트릭, 휴먼중공업, 삼강엠엔티\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 2024년 5월 29일 KNN 인물포커스에 소개되었으며, 김정엽 대표이사가 중대재해처벌법과 관련된 인터뷰를 진행하였습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 KNN 인물포커스에 소개된 날짜는 언제인가요?\",\n",
    "#         \"answers\": {\"text\": [\"2024년 5월 29일\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 태양광 발전소 조각투자 플랫폼 '햇나'를 런칭하여 블록체인 기반의 조각투자 서비스를 제공하고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 런칭한 태양광 발전소 조각투자 플랫폼의 이름은 무엇인가요?\",\n",
    "#         \"answers\": {\"text\": [\"햇나\"], \"answer_start\": [25]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 미래기술연구소, DT사업부, IoT사업부, ESG사업부, SDM실, 제조ICT사업부, 대외사업부, E플랫폼사업부, 인프라사업부, 전략기획실, 경영지원실, 기술영업실로 구성되어 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스의 조직 구성은 어떻게 되어 있나요?\",\n",
    "#         \"answers\": {\"text\": [\"미래기술연구소, DT사업부, IoT사업부, ESG사업부, SDM실, 제조ICT사업부, 대외사업부, E플랫폼사업부, 인프라사업부, 전략기획실, 경영지원실, 기술영업실\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# # Hugging Face Dataset 객체로 변환\n",
    "# dataset = Dataset.from_list(custom_data)\n",
    "\n",
    "# # 데이터 전처리\n",
    "# def preprocess_data(examples):\n",
    "#     inputs = tokenizer(examples[\"question\"], examples[\"context\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "#     inputs[\"labels\"] = tokenizer(examples[\"answers\"][\"text\"][0], truncation=True, padding=\"max_length\", max_length=512)[\"input_ids\"]\n",
    "#     return inputs\n",
    "\n",
    "# fine_tuning_dataset = dataset.map(preprocess_data)\n",
    "\n",
    "# # 학습 하이퍼파라미터 설정\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=new_model_path,  # 새로운 모델 덮어쓰기\n",
    "#     per_device_train_batch_size=1,\n",
    "#     per_device_eval_batch_size=1,\n",
    "#     num_train_epochs=10,\n",
    "#     logging_steps=1,\n",
    "#     save_total_limit=2,\n",
    "#     save_steps=1,\n",
    "#     eval_strategy=\"steps\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     fp16=True,  # GPU 최적화\n",
    "# )\n",
    "\n",
    "# # Trainer 설정\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=fine_tuning_dataset,\n",
    "#     eval_dataset=fine_tuning_dataset,\n",
    "#     processing_class=tokenizer,\n",
    "# )\n",
    "\n",
    "# print(\"Fine-tuning 시작...\")\n",
    "# trainer.train()\n",
    "# print(\"Fine-tuning 완료!\")\n",
    "\n",
    "# # 학습된 LoRA 모델 저장\n",
    "# trainer.save_model(new_model_path)  # 전체 모델 저장\n",
    "# model.save_pretrained(new_model_path)  # LoRA 가중치 저장\n",
    "# tokenizer.save_pretrained(new_model_path)\n",
    "\n",
    "# print(f\"Fine-tuned 모델이 {new_model_path}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b8c375-22ea-4a2c-8949-70e90fa51d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "# from datasets import Dataset\n",
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# # 모델 ID (Hugging Face에서 다운로드한 모델명)\n",
    "# model_id = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "\n",
    "# # 캐시된 모델의 실제 경로 찾기 (전체 다운로드)\n",
    "# original_model_path = snapshot_download(repo_id=model_id)\n",
    "\n",
    "# # 새로운 모델 저장 경로 지정\n",
    "# # new_model_path = os.path.expanduser(\"~/.cache/huggingface/hub/models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B\")\n",
    "# new_model_path = os.path.join(\"/mnt/ssd/1/hub\", \"models--iljoodeephub-Bllossom--llama-3.2-Korean-Bllossom-3B_bf16\")\n",
    "\n",
    "# # 기존 모델 & 토크나이저 로드\n",
    "# tokenizer = AutoTokenizer.from_pretrained(original_model_path)\n",
    "# tokenizer.pad_token = tokenizer.eos_token \n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     original_model_path,\n",
    "#     torch_dtype=torch.float32,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "\n",
    "# # 새로운 경로가 존재하는지 확인 후 저장\n",
    "# if not os.path.exists(new_model_path):\n",
    "#     os.makedirs(new_model_path, exist_ok=True)\n",
    "\n",
    "# # 모델과 토크나이저를 새로운 경로에 저장\n",
    "# model.save_pretrained(new_model_path)\n",
    "# tokenizer.save_pretrained(new_model_path)\n",
    "\n",
    "# print(f\"모델이 새로운 경로로 저장되었습니다: {new_model_path}\")\n",
    "\n",
    "# # 풀 튜닝을 위해 전체 파라미터 업데이트 (모델 재로드)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     new_model_path,\n",
    "#     torch_dtype=torch.float32,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "\n",
    "# # 커스텀 데이터 (SQuAD 스타일 예시)\n",
    "# custom_data = [\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 부산광역시 동래구 사직동 석사로 10-1 률영빌딩 5층에 본사를 두고 있는 디지털 혁신 전문기업이다. \",\n",
    "#         \"question\": \"일주지앤에스 알아?\",\n",
    "#         \"answers\": {\"text\": [\"부산에 위치한 디지털 혁신 전문기업\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"부산 디지털 혁신 전문기업의 대표이사는 김정엽 이다. 김정엽 대표는 경북대학교 통계학과 출신으로 현대중공업 전산실에서 근무하다가 일주지앤에스를 창업하였으며, 티허브의 공동 태표이사이기도 하다.\",\n",
    "#         \"question\": \"일주지앤에스 대표는?\",\n",
    "#         \"answers\": {\"text\": [\"김정엽\"], \"answer_start\": [22]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스 김도현 이사는 일주지앤에스의 미래기술연구소 소장이다. 김도현 이사는 AI,빅데이터,융합기술 전문가이다.\",\n",
    "#         \"question\": \"일주지앤에스 김도현 알아?\",\n",
    "#         \"answers\": {\"text\": [\"일주지앤에스의 김도현 이사는 미래기술연구소 소장이다\"], \"answer_start\": [0]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 2006년 6월 29일에 설립된 IT 서비스 전문기업으로, 부산광역시 동래구 사직동 석사로 10-1 률영빌딩 5층에 본사를 두고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스는 언제 설립되었나요?\",\n",
    "#         \"answers\": {\"text\": [\"2006년 6월 29일\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 정보시스템 통합, 소프트웨어 구축, 정보통신공사, 컴퓨터 도매, 연구개발, 시각 디자인, 전자부품 개발 및 제조 등의 다양한 사업을 영위하고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스의 주요 사업 분야는 무엇인가요?\",\n",
    "#         \"answers\": {\"text\": [\"정보시스템 통합, 소프트웨어 구축, 정보통신공사, 컴퓨터 도매, 연구개발, 시각 디자인, 전자부품 개발 및 제조\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 스마트 공장 구축, 시스템 통합(SI), IT 아웃소싱, 솔루션 개발, 컨설팅 사업 등을 주축으로 종합 정보 서비스를 제공하고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 제공하는 서비스는 무엇인가요?\",\n",
    "#         \"answers\": {\"text\": [\"스마트 공장 구축, 시스템 통합(SI), IT 아웃소싱, 솔루션 개발, 컨설팅 사업\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 현대일렉트릭, 휴먼중공업, 삼강엠엔티 등과 스마트 공장 구축 프로젝트를 성공적으로 수행하였습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 스마트 공장 구축을 수행한 기업은 어디인가요?\",\n",
    "#         \"answers\": {\"text\": [\"현대일렉트릭, 휴먼중공업, 삼강엠엔티\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 2024년 5월 29일 KNN 인물포커스에 소개되었으며, 김정엽 대표이사가 중대재해처벌법과 관련된 인터뷰를 진행하였습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 KNN 인물포커스에 소개된 날짜는 언제인가요?\",\n",
    "#         \"answers\": {\"text\": [\"2024년 5월 29일\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 태양광 발전소 조각투자 플랫폼 '햇나'를 런칭하여 블록체인 기반의 조각투자 서비스를 제공하고 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스가 런칭한 태양광 발전소 조각투자 플랫폼의 이름은 무엇인가요?\",\n",
    "#         \"answers\": {\"text\": [\"햇나\"], \"answer_start\": [25]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"context\": \"일주지앤에스는 미래기술연구소, DT사업부, IoT사업부, ESG사업부, SDM실, 제조ICT사업부, 대외사업부, E플랫폼사업부, 인프라사업부, 전략기획실, 경영지원실, 기술영업실로 구성되어 있습니다.\",\n",
    "#         \"question\": \"일주지앤에스의 조직 구성은 어떻게 되어 있나요?\",\n",
    "#         \"answers\": {\"text\": [\"미래기술연구소, DT사업부, IoT사업부, ESG사업부, SDM실, 제조ICT사업부, 대외사업부, E플랫폼사업부, 인프라사업부, 전략기획실, 경영지원실, 기술영업실\"], \"answer_start\": [8]}\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# # Hugging Face Dataset 객체로 변환\n",
    "# dataset = Dataset.from_list(custom_data)\n",
    "\n",
    "# # 데이터 전처리: 질문과 컨텍스트를 입력으로, 답변 텍스트를 라벨로 설정\n",
    "# def preprocess_data(examples):\n",
    "#     inputs = tokenizer(\n",
    "#         examples[\"question\"],\n",
    "#         examples[\"context\"],\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#         max_length=512\n",
    "#     )\n",
    "#     # 답변 텍스트를 라벨로 변환 (토큰 ID 형태)\n",
    "#     inputs[\"labels\"] = tokenizer(\n",
    "#         examples[\"answers\"][\"text\"][0],\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#         max_length=512\n",
    "#     )[\"input_ids\"]\n",
    "#     return inputs\n",
    "\n",
    "# full_tuning_dataset = dataset.map(preprocess_data)\n",
    "\n",
    "# # 학습 하이퍼파라미터 설정\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=new_model_path,             # 저장 경로\n",
    "#     per_device_train_batch_size=1,\n",
    "#     per_device_eval_batch_size=1,\n",
    "#     num_train_epochs=10,\n",
    "#     logging_steps=1,\n",
    "#     save_total_limit=2,\n",
    "#     save_steps=1,\n",
    "#     eval_strategy=\"steps\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     fp16=False,                            \n",
    "#     bf16=True\n",
    "# )\n",
    "\n",
    "# # Trainer 설정 (전체 모델의 파라미터 업데이트)\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=full_tuning_dataset,\n",
    "#     eval_dataset=full_tuning_dataset,\n",
    "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=100)] \n",
    "# )\n",
    "\n",
    "# print(\"Full tuning 시작...\")\n",
    "# trainer.train()\n",
    "# print(\"Full tuning 완료!\")\n",
    "\n",
    "# # 학습된 전체 모델 저장\n",
    "# trainer.save_model(new_model_path)\n",
    "# model.save_pretrained(new_model_path)\n",
    "# tokenizer.save_pretrained(new_model_path)\n",
    "\n",
    "# print(f\"Full tuned 모델이 {new_model_path}에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sanguk-WEz904Hl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
